---
title: "Capstone Project: Google Data Analytics Professional Certificate"
author: "Lucas Heyden"
date: "2025-05-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
### About the Company

Bellabeat is a technology company founded by Urška Sršen and Sando Mur, specializing in the manufacture of health-focused products for women. Since its establishment in 2013, Bellabeat has rapidly grown, positioning itself as an innovative brand in the smart device market. The company collects data on activity, sleep, stress, and reproductive health, empowering women to better understand their habits and make healthy decisions. With a strong digital presence, Bellabeat invests in online marketing, including ads on Google, Facebook, Instagram, and YouTube, as well as maintaining an e-commerce channel.

  

### Products

Bellabeat offers a range of products designed to monitor the health and well-being of users. These include:

- **Bellabeat App**: Provides health data related to activity, sleep, stress, menstrual cycle, and mindfulness habits.

- **Leaf**: A wellness tracker that can be worn as a bracelet, necklace, or clip, connecting to the app to track activity, sleep, and stress.

- **Time**: A wellness watch that combines classic design with smart technology to monitor activity, sleep, and stress.

- **Spring**: A water bottle that tracks daily water intake, ensuring users stay hydrated.

- **Bellabeat Subscription**: A membership program offering personalized guidance on nutrition, activity, sleep, health and beauty, and mindfulness.

  

### Stakeholders

The key stakeholders of Bellabeat include:

- **Urška Sršen**: Co-founder and Creative Director, who believes in the potential of data analysis to drive the company's growth.

- **Sando Mur**: Co-founder and mathematician, a key member of Bellabeat's executive team.

- **Marketing Analysis Team**: A team of data analysts responsible for collecting, analyzing, and reporting data that helps guide Bellabeat's marketing strategy. As a junior analyst, you are part of this team and focused on understanding how consumers use Bellabeat products to provide strategic recommendations.

## Project Deliverables

1. **Clear Summary of the Business Task**: A concise and objective description of the project’s goal, highlighting the objectives and expected outcomes.

2. **Description of All Data Sources Used**: A comprehensive overview of all data sources employed in the analysis, including the origin, nature of the data, and relevance to the business task.

3. **Documentation of Data Cleansing and Manipulation**: A detailed record of all steps taken for data cleaning and manipulation, including techniques used, transformations applied, and justifications for the decisions made.

4. **Summary of the Analysis Conducted**: An overview of the methodologies and analytical approaches employed, highlighting the key steps and techniques used to reach the conclusions.

5. **Supporting Visualizations and Key Findings**: Graphs and visualizations that illustrate the results of the analysis, accompanied by a summary of the most relevant discoveries and insights obtained.

6. **Marketing Recommendations for a Selected Product**: Strategic suggestions based on the analysis, focused on a specific product, aimed at optimizing marketing campaigns and driving sales.


## Data analysis process

### Ask

The co-founder and Creative Director of Bellabeat, Urška Sršen, has requested an analysis of smart device usage data in order to gain insights into how consumers use non-Bellabeat smart devices. Based on these insights, it will be necessary to select one Bellabeat product to apply the findings in the presentation.

The key questions that will guide this analysis are:

- **What are some trends in smart device usage?**
- **How could these trends apply to Bellabeat customers?**
- **How could these trends help influence Bellabeat's marketing strategy?**

These questions are fundamental to understanding consumer behavior and how Bellabeat can position itself more effectively in the market.


### Prepare 
#### Data storage  
This dataset was collected via Amazon Mechanical Turk between March and May 2016. It contains data from 30 Fitbit users who consented to sharing their personal fitness tracker information, including physical activity, heart rate, and sleep. The dataset, publicly available on Kaggle through Mobius, enables analysis of user habits.  

#### Organization  
The dataset consists of 18 CSV files, 15 in long format and 3 in wide format. Each user has a unique ID and the records are organized by day and time. Five files were chosen for analysis and processed in RStudio Cloud.


| File Name                           | Type | Format | Days | Users | Description |
|--------------------------------------|------|--------|------|-------|------------------------------------------------|
| dailyActivity_merged                 | CSV  | Long   | 30   | 33    | Daily activity: steps, distance, intensity, calories |
| dailyCalories_merged                 | CSV  | Long   | 30   | 33    | Daily calorie burn |
| dailyIntensities_merged              | CSV  | Long   | 30   | 33    | Daily intensity levels (minutes and distances) |
| hourlyCalories_merged                 | CSV  | Long   | 30   | 33    | Hourly calorie burn |
| sleepDay_merged                        | CSV  | Long   | 30   | 24    | Sleep records: total sleep time and time in bed |


#### Credibility  
An evaluation using the **ROCCC** method reveals: 
- **Reliability:** Low, due to a small sample size and short collection period.  
- **Originality:** Collected by third parties (MTurk) rather than directly by Fitbit.  
- **Comprehensiveness:** Limited, as demographic details are missing.  
- **Timeliness:** Outdated (2016), potentially not reflecting current trends.  
- **Citation:** Published on Zenodo.org by Furberg et al., providing some academic credibility.  

#### Licensing & Privacy  
The dataset is in the public domain (CC0), allowing free use. All personal data has been anonymized in compliance with GDPR regulations to ensure user privacy.  

#### Integrity  
*File integrity was verified using hash validation, ensuring no alterations occurred during download.  

#### Limitations  
Variations in unique IDs, differences between automated and manually entered data, and lack of standardization across devices may affect analysis. However, the insights gained can help Bellabeat enhance its products.  



### Process 
Data integrity and the cleaning process are essential in data analysis, ensuring that data is accurate, consistent, and reliable. Data cleaning involves identifying and correcting errors or inconsistencies, which enhances the quality of insights derived from the data. In this discussion, we will explore several critical aspects of data integrity and the data cleaning process. The following points will be addressed:

- The tools selected for data cleaning and the rationale behind those choices;
- Methods employed to ensure the integrity of the data;
- Steps taken to maintain a clean dataset;
- Verification processes to confirm that the data is ready for analysis;
- Documentation of the cleaning process for future reference and sharing.

These elements are vital for ensuring that the data used in analysis is of high quality, ultimately leading to more accurate and actionable insights.

#### Tool used
For the analysis, I will be using R, a powerful and efficient tool for data processing, cleaning, and visualization. R is widely recognized for its extensive libraries and packages, such as `dplyr` for data manipulation and `ggplot2` for creating stunning visualizations. Its ability to handle large datasets and perform complex statistical analyses makes it one of the most popular programming languages in the data science community today. Additionally, R's open-source nature allows for continuous improvement and a vibrant community that contributes to its vast ecosystem of resources. This makes R an ideal choice for ensuring high-quality data analysis.

#### Loading libraries and importing files
```{r cars}
library(tidyverse)
library(lubridate)
library(ggplot2)
library(ggrepel)
library(readr)
library(dplyr)
library(tidyr)
library(here)
library(skimr)
library(janitor)
library(corrplot)
library(ggcorrplot)
library(cluster)
library(factoextra)

df_daily_activity <- read_csv("/cloud/project/raw_data_bellabeat/dailyActivity_merged.csv")
df_daily_calories <- read_csv("/cloud/project/raw_data_bellabeat/dailyCalories_merged.csv")
df_daily_intensities <- read_csv("/cloud/project/raw_data_bellabeat/dailyIntensities_merged.csv")
df_daily_sleep <- read_csv("/cloud/project/raw_data_bellabeat/sleepDay_merged.csv")
df_hourly_calories <- read_csv("/cloud/project/raw_data_bellabeat/hourlyCalories_merged.csv")
```


#### Exploratory analisys
```{r}
str(df_daily_activity)

str(df_daily_sleep)

str(df_daily_intensities)

str(df_daily_calories)

str(df_hourly_calories)
```

#### Data preparation

***
**Daily Activity**

```{r}
df_daily_activity$ActivityDate <- as.Date(df_daily_activity$ActivityDate, format = "%m/%d/%Y")
df_daily_activity$Id <- as.character(df_daily_activity$Id)
df_daily_activity <- df_daily_activity %>% clean_names()
```

Each Id corresponds to a user, so the Id is not unique in the dataframe, and it is not possible to use it as a primary key for linking or checking for duplication.
```{r}
n_distinct(df_daily_activity$id) == nrow(df_daily_activity)

n_distinct(df_daily_activity$id)
nrow(df_daily_activity)
```

As it was verified that the Id is not unique, a uniqueness and non-null validation will be performed based on the column values.

```{r}
dp_daily_activity <- sum(duplicated(df_daily_activity)) * 100 / nrow(df_daily_activity)
na_daily_activity <- sum(is.na(df_daily_activity)) * 100 / nrow(df_daily_activity)

dp_daily_activity
na_daily_activity
```

Since there are no duplicate rows in the dataset, there is no need to remove any. So, next, the 'Id' column will be renamed to fk_daily_activity so that it can be used as a foreign key if needed, and a new Id column will be generated which is the concatenation of fk_daily_activity and activity_date. Considering that all data sets have the characteristic of the Id not being unique in the dataframe, a new Id will always be generated through the concatenation of columns.

```{r}
df_daily_activity <- df_daily_activity %>%
  rename(fk_daily_activity = id)

df_daily_activity <- df_daily_activity %>%
  mutate(id = paste(fk_daily_activity, activity_date, sep = "_"))

df_daily_activity <- df_daily_activity %>%
  relocate(id, .before = fk_daily_activity)

n_distinct(df_daily_activity$id) == nrow(df_daily_activity)

n_distinct(df_daily_activity$id)
nrow(df_daily_activity)
```

Creation of the difference column between the total distance and the distance tracked by the application.

```{r}
df_daily_activity <- df_daily_activity %>%
  mutate(delta_distances = total_distance - tracker_distance)
```

Assessment of the amount of data by which the actual distance diverges from the tracked distance.
```{r}
df_daily_activity %>%
  mutate(delta_group = case_when(
    delta_distances == 0 ~ "0",
    delta_distances > 0 & delta_distances <= 0.5 ~ "0–0.5",
    delta_distances > 0.5 & delta_distances <= 1 ~ "0.5–1",
    delta_distances > 1 & delta_distances <= 1.5 ~ "1–1.5",
    delta_distances > 1.5 ~ ">1.5"
  )) %>%
  group_by(delta_group) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100, 2)) -> delta_summary
  
delta_summary
```

Since the difference between the actual distance and the distance recorded by the device is greater than zero in less than 2% of the analyzed sample, we will proceed with the analysis excluding these cases. This ensures that the evaluated data reflects more accurate measurements.

```{r}
df_daily_activity <- df_daily_activity %>% filter(delta_distances == 0)
```


Adding weekday number and weekday name.
```{r}
df_daily_activity <- df_daily_activity %>%
  mutate(
    week_day_name = weekdays(activity_date),
    # 0 = Sunday, 1 = Monday, ..., 6 = Saturday
    week_day_number = as.integer(format(activity_date, "%w")) 
  )
```



At the end of processing this was the final dataframe.
```{r}
str(df_daily_activity)
```

Based on this dataframe, df_users_activity will be created, which will show the percentage of days in which each user was active. Considering the OMS recommendation of at least 7,000 steps per day, this will be the criterion adopted to define whether a user had an active day or not.

```{r}
user_active_dates <- df_daily_activity %>%
  filter(total_steps > 7000) %>%
  group_by(fk_daily_activity) %>%
  summarise(active_days = n(), .groups = "drop")


user_all_dates <- df_daily_activity %>%
  group_by(fk_daily_activity) %>%
  summarise(total_days = n(), .groups = "drop")

df_user_activity <- user_all_dates %>%
  left_join(user_active_dates, by = "fk_daily_activity") %>%
  mutate(
    id_user = fk_daily_activity,
    active_days = coalesce(active_days, 0),
    user_activity_in_period = (active_days * 100) / total_days
  ) %>%
  select(id_user, user_activity_in_period) %>%
  arrange(desc(user_activity_in_period)) 



df_user_activity
```

Performing processing to plot the activity graph by time of day.

```{r}
# Create a weekday column
weekday_levels <- c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")
df_daily_activity <- df_daily_activity %>%
  mutate(
    # Convert the weekday to a factor with the correct order
    weekday = factor(weekdays(activity_date), levels = weekday_levels)
  )

# Calculate the average of active minutes by activity type and weekday, then reshape to long format
avg_active_minutes_long <- df_daily_activity %>%
  group_by(weekday) %>%
  summarise(
    Lightly_Active = mean(lightly_active_minutes, na.rm = TRUE),
    Fairly_Active = mean(fairly_active_minutes, na.rm = TRUE),
    Very_Active = mean(very_active_minutes, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # Convert wide to long format for plotting
  pivot_longer(
    cols = c(Lightly_Active, Fairly_Active, Very_Active),
    names_to = "activity_type",
    values_to = "avg_minutes"
  ) %>%
  # Set factor levels and labels for activity_type
  mutate(
    activity_type = factor(activity_type, levels = c("Lightly_Active", "Fairly_Active", "Very_Active"),
                          labels = c("Lightly Active", "Fairly Active", "Very Active"))
  ) %>%
  # Remove rows with NA weekday (if any)
  filter(!is.na(weekday))

```



Processing data to calculate correlations between total_distance and each active distance type.
```{r}
# Calculate the proportion of each active distance type relative to total_distance
df_dist_composition <- df_daily_activity %>%
  mutate(
    prop_light = light_active_distance / total_distance,
    prop_moderate = moderately_active_distance / total_distance,
    prop_very_active = very_active_distance / total_distance
  )

# Calculate correlations between total_distance and each active distance type
cor(df_daily_activity$total_distance, df_daily_activity$light_active_distance, use = "complete.obs")
cor(df_daily_activity$total_distance, df_daily_activity$moderately_active_distance, use = "complete.obs")
cor(df_daily_activity$total_distance, df_daily_activity$very_active_distance, use = "complete.obs")

# Prepare data in long format for plotting daily composition
df_dist_long <- df_dist_composition %>%
  select(activity_date, total_distance, light_active_distance, moderately_active_distance, very_active_distance) %>%
  pivot_longer(
    cols = c(light_active_distance, moderately_active_distance, very_active_distance),
    names_to = "distance_type",
    values_to = "distance"
  )
```




***
**Daily Sleep**

Validation of non-unique and null values.
```{r}
dp_daily_sleep <- sum(duplicated(df_daily_sleep)) * 100 / nrow(df_daily_sleep)
na_daily_sleep <- sum(is.na(df_daily_sleep)) * 100 / nrow(df_daily_sleep)

dp_daily_sleep
na_daily_sleep
```

Since df_daily_sleep has duplicate data and there is little of it, only non-duplicated data will be considered in the analysis.
```{r}
df_daily_sleep <- df_daily_sleep %>% 
  distinct()
```

Separating date and time.
```{r}
df_daily_sleep$Id <- as.character(df_daily_sleep$Id)

df_daily_sleep <- df_daily_sleep %>%
  separate(SleepDay, into = c("sleep_date", "sleep_hour"), sep = " ")

df_daily_sleep$sleep_date <- as.Date(df_daily_sleep$sleep_date, format = "%m/%d/%Y")


df_daily_sleep <- df_daily_sleep %>% clean_names()


str(df_daily_sleep)
```

Creating a new Id, as was done in df_daily_activity.
```{r}
df_daily_sleep <- df_daily_sleep %>%
  rename(fk_daily_sleep = id)

df_daily_sleep <- df_daily_sleep %>%
  mutate(id = paste(fk_daily_sleep, sleep_date, sep = "_"))

df_daily_sleep <- df_daily_sleep %>%
  relocate(id, .before = fk_daily_sleep)

n_distinct(df_daily_sleep$id) == nrow(df_daily_sleep)

n_distinct(df_daily_sleep$id)
nrow(df_daily_sleep)
```

This is the result after processing df_daily_sleep.
```{r}
str(df_daily_sleep)
```

Incorporating average sleep into the dataframe with consolidated user data.
```{r}
df_avg_sleep <- df_daily_sleep %>%
  group_by(fk_daily_sleep) %>%
  summarise(avg_minutes_asleep = mean(total_minutes_asleep, na.rm = TRUE), .groups = "drop") %>%
  rename(id_user = fk_daily_sleep)



df_user_activity <- df_user_activity %>%
  left_join(df_avg_sleep, by = c("id_user" = "id_user")) %>%
  select(id_user, user_activity_in_period, avg_minutes_asleep)

df_user_activity
```


***
**Daily Calories**

Validation of non-unique and null values.
```{r}
dp_daily_calories <- sum(duplicated(df_daily_calories)) * 100 / nrow(df_daily_calories)
na_df_daily_calories <- sum(is.na(df_daily_calories)) * 100 / nrow(df_daily_calories)

dp_daily_calories
na_df_daily_calories

str(df_daily_calories)
```

Processing the dataframe data so that it is standardized.

```{r}
df_daily_calories$ActivityDate <- as.Date(df_daily_calories$ActivityDay, format = "%m/%d/%Y")
df_daily_calories$Id <- as.character(df_daily_calories$Id)
df_daily_calories <- df_daily_calories %>% 
  clean_names() %>%
  select(id, activity_date, calories) %>%
  rename(id_user = id) %>%
  mutate(id = paste(id_user, activity_date, sep = "_")) %>%
  relocate(id, .before = id_user)
df_daily_calories
```

Measuring the sleep efficiency.
```{r}
# 1. Create a metric for sleep inefficiency (time in bed but not asleep)
df_sleep_efficiency <- df_daily_sleep %>%
  mutate(
    sleep_gap = total_time_in_bed - total_minutes_asleep  # minutes awake while in bed
  ) %>%
  rename(
    activity_date = sleep_date,   # rename for joining consistency
    id_user = fk_daily_sleep      # rename to match the other dataset
  ) %>%
  select(id_user, activity_date, sleep_gap)

# Creating the Id column
df_sleep_efficiency <- df_sleep_efficiency %>%
  mutate(id = str_c(id_user, activity_date, sep = "_")) %>%
  relocate(id, .before = id_user)

str(df_sleep_efficiency)

# 2. Join with daily calories to compare sleep and activity
df_sleep_calories <- df_sleep_efficiency %>%
  inner_join(df_daily_calories, by = c("id_user", "activity_date"))
```



Aggregating average calories burned by users in df_user_activity
```{r}
df_avg_user_calories <- df_daily_calories %>%
  group_by(id_user) %>%
  summarise(avg_calories = mean(calories, na.rm = TRUE))

df_user_activity <- df_user_activity %>%
  left_join(df_avg_user_calories, by = c("id_user" = "id_user")) %>%
  select(id_user, user_activity_in_period, avg_minutes_asleep, avg_calories)

str(df_user_activity)
```


***
**Daily Intensities**
Validation of non-unique and null values.
```{r}
dp_daily_intensities <- sum(duplicated(df_daily_intensities)) * 100 / nrow(df_daily_intensities)
na_daily_intensities <- sum(is.na(df_daily_intensities)) * 100 / nrow(df_daily_intensities)

dp_daily_intensities
na_daily_intensities

str(df_daily_intensities)
```


```{r}
str(df_daily_intensities)
```



Processing the dataframe data so that it is standardized.
```{r}
df_daily_intensities <- df_daily_intensities %>%
  clean_names() %>%
  rename(id_user = id) %>%
  rename(intensities_date = activity_day) %>%
  mutate(
    intensities_date = mdy(intensities_date),  # converte string para Date
    id = paste(id_user, intensities_date, sep = "_")  # cria o id padronizado
  ) %>%
  relocate(id, .before = id_user)%>%
  mutate(id_user = as.character(id_user))

str(df_daily_intensities)
```

Processing data to canculate the correlation betwen intenditie of some activity and time in bed without sleep. 
```{r}
df_intensity_sleep <- df_sleep_efficiency %>%
  inner_join(df_daily_intensities, by = "id")

df_corr <- df_intensity_sleep %>%
  select(
    sleep_gap,
    lightly_active_minutes,
    fairly_active_minutes,
    very_active_minutes
  )

# Calcular matriz de correlação
correlation_matrix <- cor(df_corr, use = "complete.obs")
print(correlation_matrix)

```






Aggregating average calories burned by users in df_user_activity
```{r}
df_avg_user_intensities <- df_daily_intensities %>%
  group_by(id_user) %>%
  summarise(
    avg_lightly_active_minutes = mean(lightly_active_minutes, na.rm = TRUE),
    avg_fairly_active_minutes = mean(fairly_active_minutes, na.rm = TRUE),
    avg_very_active_minutes = mean(very_active_minutes, na.rm = TRUE),
    avg_sedentary_active_distance = mean(sedentary_active_distance, na.rm = TRUE),
    avg_light_active_distance = mean(light_active_distance, na.rm = TRUE),
    avg_moderately_active_distance = mean(moderately_active_distance, na.rm = TRUE),
    avg_very_active_distance = mean(very_active_distance, na.rm = TRUE)
  )

df_user_activity <- df_user_activity %>%
  left_join(df_avg_user_intensities, by = "id_user") %>%
  select(
    id_user,
    user_activity_in_period,
    avg_minutes_asleep,
    avg_calories,
    avg_lightly_active_minutes,
    avg_fairly_active_minutes,
    avg_very_active_minutes,
    avg_sedentary_active_distance,
    avg_light_active_distance,
    avg_moderately_active_distance,
    avg_very_active_distance
  )

str(df_user_activity)
```


***
**Hourly Calories**
Validation of non-unique and null values
```{r}
# Calculate the percentage of duplicated and missing values
dp_hourly_calories <- sum(duplicated(df_hourly_calories)) * 100 / nrow(df_hourly_calories)
na_hourly_calories <- sum(is.na(df_hourly_calories)) * 100 / nrow(df_hourly_calories)

dp_hourly_calories
na_hourly_calories

str(df_hourly_calories)
```

Processing the dataframe to standardize columns
```{r}
df_hourly_calories$activity_datetime <- as.POSIXct(
  df_hourly_calories$ActivityHour,
  format = "%m/%d/%Y %I:%M:%S %p"
)

df_hourly_calories$hour <- hour(df_hourly_calories$activity_datetime)

df_hourly_calories <- df_hourly_calories %>%
  clean_names() %>%
  select(id, calories, activity_datetime, hour) %>%
  rename(id_user = id) %>%
  mutate(id = paste(id_user, activity_datetime, sep = "_")) %>%
  relocate(id, .before = id_user) %>%
  mutate(activity_date = format(activity_datetime, "%d/%m/%Y"))

df_hourly_calories <- df_hourly_calories %>%
  arrange(desc(hour))
head(df_hourly_calories,100)
```

Performing processing to plot the graph of active users by time of day based on calorie expenditure. It was considered that an active user is one who spent 200 calories in that hour, given that, according to the article "Understanding METs: A Simple Way to Measure Exercise Intensity" from ACE Fitness, this would correspond to a light activity practiced for 1 hour by a person weighing 67kg. We consider these to be reasonable parameters, as according to the Size USA study, this is the average weight of American women.

```{r}
# Create a column with date only (remove time)
df_hourly_calories <- df_hourly_calories %>%
  mutate(activity_date = as.Date(activity_datetime))

# Classify each record as Active (>200) or Sedentary (<=200)
df_hourly_calories <- df_hourly_calories %>%
  mutate(activity_segment = ifelse(calories > 200, "Active", "Sedentary"))

# For each user and hour, define the status for that hour (prioritize 'Active')
user_hour_status <- df_hourly_calories %>%
  group_by(id_user, hour) %>%
  summarise(
    is_active = any(activity_segment == "Active"),
    .groups = "drop"
  ) %>%
  mutate(activity_segment = ifelse(is_active, "Active", "Sedentary"))

# Count the number of users per hour and activity status
users_by_hour_status <- user_hour_status %>%
  group_by(hour, activity_segment) %>%
  summarise(user_count = n(), .groups = "drop")

# Ensure factor order for activity_segment
users_by_hour_status$activity_segment <- factor(users_by_hour_status$activity_segment,
                                                levels = c("Sedentary", "Active"))
```

### Analyze & Share

#### Distribution of User Activity Levels

The sample shows great diversity among users: from completely sedentary to highly active. This is positive, as it allows for more balanced and unbiased analyses.

- **Reflection**: The wide variation indicates multiple user profiles, from occasional to fully engaged users.

```{r}
ggplot(df_user_activity, aes(x = user_activity_in_period)) +
  geom_histogram(binwidth = 10, fill = "#00BFC4", color = "black", alpha = 0.7) +
  labs(
    title = "Distribution of User Activity Levels (%)",
    x = "% of Active Days",
    y = "Number of Users"
  ) +
  theme_minimal()
```



**Analysis of user activity by day of the week.**

Active Minutes by Type and Day of the Week

Most active minutes recorded are of low intensity (“Lightly Active”) across all days. Few minutes are spent in moderate or vigorous activities.

**Reflection:** Users favor light movement with minimal high-intensity activity.


```{r}
ggplot(avg_active_minutes_long, aes(x = weekday, y = avg_minutes, fill = activity_type)) +
  geom_col(position = "dodge", color = "black", alpha = 0.9) +
  labs(
    title = "Average Active Minutes by Day of the Week and Activity Type",
    x = "Day of the Week",
    y = "Average Active Minutes",
    fill = "Activity Type"
  ) +
  theme_minimal()
```





**Analysis of active users by time of day based on calorie expenditure.**

Users are most active between 9 AM and 7 PM, peaking around 11 AM–2 PM. Outside these hours, sedentary behavior dominates.

**Reflection:** Activity aligns with work or study schedules, indicating integration into daily routines.

```{r}
ggplot(users_by_hour_status, aes(x = hour, y = user_count, fill = activity_segment)) +
  geom_col(color = "black", alpha = 0.85) +
  scale_fill_manual(values = c("Sedentary" = "#6baed6", "Active" = "#fd8d3c")) +
  scale_x_continuous(breaks = 0:23) +
  labs(
    title = "Active vs Sedentary Users by Hour of the Day",
    x = "Hour of the Day",
    y = "Number of Users",
    fill = "Status"
  ) +
  theme_minimal()

```


**Analysis of correlation between total distance and each active distance type.**
Daily distance covered is predominantly from light activities. Moderate and vigorous distances are less frequent.

**Reflection:** Total daily distance largely comes from low-intensity activities, showing a preference for light exercise.

```{r}
# Stacked bar plot per day - shows composition of distances by activity type
ggplot(df_dist_long, aes(x = activity_date, y = distance, fill = distance_type)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Distance Composition by Activity Type",
    x = "Date",
    y = "Distance (km)",
    fill = "Activity Type"
  ) +
  scale_fill_manual(
    values = c(
      "light_active_distance" = "#a1d99b",
      "moderately_active_distance" = "#fd8d3c",
      "very_active_distance" = "#e31a1c"
    ),
    labels = c(
      "light_active_distance" = "Light",
      "moderately_active_distance" = "Moderate",
      "very_active_distance" = "Very Active"
    )
  ) +
  theme_minimal()


```
**4. Calculate correlation between calories burned and sleep gap**
There is a slight negative correlation between calories burned and time spent awake in bed.

**Reflection:** Higher daily energy expenditure appears linked to shorter awake time, suggesting physical activity enhances sleep efficiency.
```{r}
# 3. Plot the relationship between calories burned and sleep inefficiency
ggplot(df_sleep_calories, aes(x = calories, y = sleep_gap)) +
  geom_point(alpha = 0.6) +  # scatter plot with transparency
  geom_smooth(method = "lm", se = TRUE, color = "blue") +  # linear regression line
  labs(
    title = "Daily Calories vs. Time Awake in Bed",
    x = "Calories Burned",
    y = "Minutes Awake in Bed"
  ) +
  theme_minimal()
```


**Analysis of correlation between activity kind and time to sleep.**
Activity Intensity vs. Time Awake

**Lightly Active:** Slight negative correlation.

**Fairly Active:** Minor positive correlation.

**Very Active:** Mild negative correlation.

**Reflection:** Light and vigorous activities demonstrate opposite effects on awake time, while moderate shows a less clear relationship.
```{r}
# Lightly Active
ggplot(df_intensity_sleep, aes(x = lightly_active_minutes, y = sleep_gap)) +
  geom_point(alpha = 0.6, color = "black") +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  labs(
    title = "Lightly Active vs. Time Awake in Bed",
    x = "Minutes Lightly Active",
    y = "Minutes Awake in Bed"
  ) +
  theme_minimal()

# Fairly Active
ggplot(df_intensity_sleep, aes(x = fairly_active_minutes, y = sleep_gap)) +
  geom_point(alpha = 0.6, color = "black") +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  labs(
    title = "Fairly Active vs. Time Awake in Bed",
    x = "Minutes Fairly Active",
    y = "Minutes Awake in Bed"
  ) +
  theme_minimal()

# Very Active
ggplot(df_intensity_sleep, aes(x = very_active_minutes, y = sleep_gap)) +
  geom_point(alpha = 0.6, color = "black") +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  labs(
    title = "Very Active vs. Time Awake in Bed",
    x = "Minutes Very Active",
    y = "Minutes Awake in Bed"
  ) +
  theme_minimal()
```

## Share

Based on our analysis, we observed the following key insights:

1. **Midday Activity Peak and Extended Sedentary Periods**  
   Users are most active between 11 AM and 2 PM, but show prolonged sedentary behavior in the early morning and late afternoon.

2. **Dominance of Light Activity**  
   The majority of active minutes come from low-intensity movement, with moderate and vigorous activities being much less frequent.

3. **Light Activity as Main Contributor to Daily Distance**  
   Daily distance covered is largely driven by light walking, indicating a preference for gentle movement.

4. **Calorie Burn Correlates to Sleep Efficiency**  
   Higher daily calorie expenditure is associated with shorter awake time in bed, suggesting that more active days lead to smoother transitions to sleep.

5. **Intensity-Specific Sleep Effects**  
   - Light activity shows a slight negative correlation with time awake in bed.  
   - Moderate activity has a minor positive correlation, potentially disrupting sleep if done too late.  
   - Vigorous activity correlates negatively with awake time, indicating it aids faster sleep onset.

---

## Act

To translate these insights into strategic initiatives for Bellabeat, we recommend the following campaigns and features:

1. **“Move More” Habit Builder**  
   - Send in-app reminders at 9 AM and 3 PM to break up sedentary stretches.  
   - Leverage the Leaf tracker for quick activity prompts and remind users to stand or walk.

2. **Personalized Mini-Workouts**  
   - Introduce 5–10 minute HIIT and stretching routines timed to each user’s active window.  
   - Deliver suggestions through the Time watch notifications for seamless integration.

3. **“Burn & Bed” Sleep Improvement Series**  
   - Publish short videos and in-app modules pairing calorie-burning exercises with sleep tips.  
   - Highlight user sleep score improvements using Bellabeat app and Time data.

4. **Community “Light Moves” Campaign**  
   - Launch a one-week challenge encouraging users to log 20 minutes of walking each morning.  
   - Feature participant stories in newsletters and award badges in the app.

5. **Intensity-Tailored Advice Cards**  
   - Deploy daily tips based on user intensity data:  
     * **Light:** Post-lunch stroll recommendations.  
     * **Moderate:** Suggest evening yoga instead of late runs.  
     * **Vigorous:** Encourage evening workouts with a two-hour buffer before bedtime.

6. **Smart Engagement Metrics**  
   - Track reminder interactions, workout completion rates, challenge participation, and sleep-gap changes.  
   - Use these metrics to iterate campaigns and refine messaging tone.

---

## Conclusion

By implementing app features that continuously address users’ most deficient areas—enhancing daily movement, personalized workouts, better sleep routines, and targeted tips—Bellabeat elevates its product exclusivity. These additions not only improve quality of life but also position Bellabeat as a proactive partner in each user’s wellness journey.

## References
ACE Fitness. Understanding METs: A Simple Way to Measure Exercise Intensity. Available at: https://www.acefitness.org/fitness-articles/4370/understanding-mets-a-simple-way-to-measure-exercise-intensity/

TC² (Textile/Clothing Technology Corporation). Size USA Study. Available at: https://www.tc2.com/size-usa.html
